{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import tarfile\n",
    "import pydicom\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"/home/data/madlab/McMakin_EMUR01/dset\"\n",
    "dicomDir = \"/home/data/madlab/McMakin_EMUR01/sourcedata\"\n",
    "\n",
    "outDir = \"/home/data/madlab/McMakin_EMUR01/derivatives/nda_templates\"\n",
    "ndaTemplate = os.path.join(outDir,\"image03_example.csv\")\n",
    "outFile = os.path.join(outDir,\"image03_template.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"List scans in session\"\"\"\n",
    "def MkScanList(subj, sess):\n",
    "    h_sessList = []\n",
    "    h_sessDir = os.path.join(dataDir, subj, sess)\n",
    "    for content in os.listdir(h_sessDir):\n",
    "        holdContent = h_sessDir + \"/\" + content\n",
    "        if os.path.isdir(holdContent):\n",
    "            h_sessList.append(content)\n",
    "    return h_sessList\n",
    "\n",
    "\"\"\"List json files in scan dir\"\"\"\n",
    "def MkJsonList(subj, sess, scan):\n",
    "    h_jsonList = []\n",
    "    h_scanDir = os.path.join(dataDir, subj, sess, scan)\n",
    "    for files in os.listdir(h_scanDir):\n",
    "        if files.endswith('.json'):\n",
    "            h_jsonList.append(files)\n",
    "    return h_jsonList\n",
    "\n",
    "\"\"\"Append csv, will only append columns with input cols\n",
    "\ti.e. allows for missing cells, so only desired info\n",
    "\tcan be written for reach row\"\"\"\n",
    "def AppendCsv(file_name, dict_of_elem, field_names):\n",
    "    with open(file_name, 'a+') as write_obj:\n",
    "        dict_writer = csv.writer(write_obj)\n",
    "        dict_writer = csv.DictWriter(write_obj, fieldnames = field_names)\n",
    "        dict_writer.writerow(dict_of_elem)\n",
    "\n",
    "\"\"\"Prepend csv, to add \"image,03\" to first row of output csv\"\"\"\n",
    "def PrependLine(file_name, line):\n",
    "    dummy_file = file_name + '.bak'\n",
    "    with open(file_name, 'r') as read_obj, open(dummy_file, 'w') as write_obj:\n",
    "        write_obj.write(line + '\\n')\n",
    "        for line in read_obj:\n",
    "            write_obj.write(line)\n",
    "    os.remove(file_name)\n",
    "    os.rename(dummy_file, file_name)\n",
    "\n",
    "\"\"\"Calc age in months, round month\n",
    "\tAccount for scanning earlier in year than bday,\n",
    "\tand add a month if participant > age+15 days at \n",
    "\ttime of acq (round to nearest chron month per reqs).\n",
    "\t\tdatetime is for punks.\"\"\"\n",
    "def CalcAge(acqString, bdayString):\n",
    "    \n",
    "    \"\"\"split, convert input\"\"\"\n",
    "    acqYear = int(acqString[:4])\n",
    "    acqMonth = int(acqString[4:6])\n",
    "    acqDay = int(acqString[6:])\n",
    "\n",
    "    bdayYear = int(bdayString[:4])\n",
    "    bdayMonth = int(bdayString[4:6])\n",
    "    bdayDay = int(bdayString[6:])\n",
    "\n",
    "    \"\"\"determine num years and months\"\"\"\n",
    "    if acqMonth > bdayMonth:\n",
    "        numYears = acqYear - bdayYear\n",
    "        numMonths = acqMonth - bdayMonth\n",
    "    else:\n",
    "        numYears = acqYear - bdayYear - 1\n",
    "        numMonths = 12 + acqMonth - bdayMonth\n",
    "\n",
    "    \"\"\"Determine if it has been more than 15 days between\n",
    "        birth day and scan, add 1 month or 0 accordingly.\n",
    "        Ugly, but I rival you to find a better solution\"\"\"\n",
    "    monthAdd = 0\n",
    "    if acqDay >= bdayDay:\n",
    "        if (acqDay - bdayDay) > 15:\n",
    "            monthAdd = 1\n",
    "    else:\n",
    "        if (30 + acqDay - bdayDay) > 15:\n",
    "            monthAdd = 1\n",
    "\n",
    "    output = 12 * numYears + numMonths + monthAdd\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A highly repetitive dict of SeriesDescriptions from\n",
    "\tjson file. All scans acquired in ses-1/2\"\"\"\n",
    "imageDict = {\n",
    "    \"dMRI\" : [\"DWI\"],\n",
    "    \"T1w_MPR_vNav\" : [\"MP-RAGE\"],\n",
    "    \"pd_tse_Cor_T2_PDHR_FCS\" : [\"PD\"],\n",
    "    \"fMRI_Emotion_REST\" : [\"fMRI\", \"resting_state\", \"rs\"],\n",
    "    \"fMRI_Emotion_PS_Study_1\" : [\"fMRI\", \"emotion_encode\", \"run-1\"],\n",
    "    \"fMRI_Emotion_PS_Study_2\" : [\"fMRI\", \"emotion_encode\", \"run-2\"],\n",
    "    \"fMRI_Emotion_PS_Test_1\" : [\"fMRI\", \"emotion_test\", \"run-1\"],\n",
    "    \"fMRI_Emotion_PS_Test_2\" : [\"fMRI\", \"emotion_test\", \"run-2\"],\n",
    "    \"fMRI_Emotion_PS_Test_3\" : [\"fMRI\", \"emotion_test\", \"run-3\"],\n",
    "    \"fMRI_DistortionMap_AP_Rest\" : [\"fMRI\", \"resting_state_field_map_AP\", \"fmap\"],\n",
    "    \"fMRI_DistortionMap_PA_Rest\" : [\"fMRI\", \"resting_state_field_map_PQ\", \"fmap\"],\n",
    "    \"fMRI_DistortionMap_AP_PS_STUDY\" : [\"fMRI\", \"emotion_encoding_field_map_AP\", \"fmap\"],\n",
    "    \"fMRI_DistortionMap_PA_PS_STUDY\" : [\"fMRI\", \"emotion_encoding_field_map_PS\", \"fmap\"],\n",
    "    \"fMRI_DistortionMap_AP_Test\" : [\"fMRI\", \"emotion_test_field_map_AP\", \"fmap\"],\n",
    "    \"fMRI_DistortionMap_PA_Test\" : [\"fMRI\", \"emotion_test_field_map_PA\", \"fmap\"],\n",
    "    \"dMRI_DistortionMap_AP_dMRI\" : [\"DWI\", \"field_map_AP\"],\n",
    "    \"dMRI_DistortionMap_PA_dMRI\" : [\"DWI\", \"field_map_PA\"]\n",
    "}\n",
    "\n",
    "\"\"\"put value of imageDict into req format for scan_type\"\"\"\n",
    "scanDict = {\n",
    "    \"DWI\" : \"multi-shell DTI\",\n",
    "    \"MP-RAGE\" : \"MPRAGE\",\n",
    "    \"fMRI\" : \"fMRI\",\n",
    "    \"PD\" : \"PD\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"get column names\"\"\"\n",
    "with open(ndaTemplate) as fd:\n",
    "    reader = csv.reader(fd)\n",
    "    holdCols = [row for idx, row in enumerate(reader) if idx == 1]\n",
    "\n",
    "ndaColumns = holdCols[0]\n",
    "# print(ndaColumns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-4015\n",
      "sub-4127\n",
      "sub-4050\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/data/madlab/McMakin_EMUR01/derivatives/nda_templates/home/data/madlab/McMakin_EMUR01/sourcedata/McMakin_EMU-000-R01_4050S2-S2/scans/1-localizer_32ch/resources/DICOM/files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-0d6d14fbe7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m             files from same scan session will share much information\"\"\"\n\u001b[1;32m     37\u001b[0m             \u001b[0mdicomPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"home/data/madlab/McMakin_EMUR01/sourcedata\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarString\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scans/1-localizer_32ch/resources/DICOM/files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mdicomList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicomPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mdicomHold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicomPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicomList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mdicomHead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicomHold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/data/madlab/McMakin_EMUR01/derivatives/nda_templates/home/data/madlab/McMakin_EMUR01/sourcedata/McMakin_EMU-000-R01_4050S2-S2/scans/1-localizer_32ch/resources/DICOM/files'"
     ]
    }
   ],
   "source": [
    "\"\"\"start new csv\"\"\"\n",
    "with open(outFile, 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(ndaColumns)\n",
    "\n",
    "\"\"\"get list of subjects\"\"\"\n",
    "subjList = [i for i in os.listdir(dataDir) if 'sub-' in i]\n",
    "\n",
    "for i in subjList:\n",
    "# i = subjList[1]\n",
    "    print(i)\n",
    "\n",
    "    \"\"\"get list of sessions\"\"\"\n",
    "    subNum = i[4:]\n",
    "    sessList = os.listdir(os.path.join(dataDir, i))\n",
    "    for j in sessList:\n",
    "    #     print(j)\n",
    "\n",
    "        \"\"\"temporarily unpack small reference dir from tar ball\"\"\"\n",
    "        sesNum = j[4:]\n",
    "        tarString = \"McMakin_EMU-000-R01_\" + subNum + sesNum + \"-\" + sesNum + \".tar.gz\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"quick patch for dataset problems\"\"\"\n",
    "        \"\"\"TODO fix dataset!\"\"\"\n",
    "        \"\"\"This breaks because not every file has the same hierarchy\"\"\"\n",
    "        if os.path.exists(os.path.join(dicomDir,tarString)):\n",
    "            tarBall = tarfile.open(os.path.join(dicomDir,tarString),'r')\n",
    "            for member in tarBall.getmembers():\n",
    "                if \"1-localizer_32ch\" in member.name:\n",
    "                    tarBall.extract(member, outDir)\n",
    "                    \n",
    "                    \n",
    "\n",
    "            \"\"\"determine, pull dicom header\n",
    "            files from same scan session will share much information\"\"\"\n",
    "            dicomPath = os.path.join(outDir, \"home/data/madlab/McMakin_EMUR01/sourcedata\", tarString[:-7], \"scans/1-localizer_32ch/resources/DICOM/files\")\n",
    "            dicomList = os.listdir(dicomPath)\n",
    "            dicomHold = os.path.join(dicomPath, dicomList[0])\n",
    "            dicomHead = pydicom.read_file(dicomHold)\n",
    "\n",
    "\n",
    "            \"\"\" extract, format some values that are consistent across session interview_date\"\"\"\n",
    "            acqHold = dicomHead.AcquisitionDate\n",
    "            acqDate = acqHold[4:6] + \"/\" + acqHold[6:] + \"/\" + acqHold[:4]\n",
    "\n",
    "            \"\"\" interview_age\"\"\"\n",
    "            bdayHold = dicomHead[0x10,0x30].value\n",
    "            numMonths = CalcAge(acqHold, bdayHold)\n",
    "\n",
    "            \"\"\" scan types per session\"\"\"\n",
    "            scanList = MkScanList(i, j)\n",
    "            for k in scanList:\n",
    "\n",
    "                \"\"\" scans per scan type\"\"\"\n",
    "                jsonList = MkJsonList(i, j, k)\n",
    "                for m in jsonList:\n",
    "\n",
    "                    \"\"\" fill rowDict with image03 required info\n",
    "                             pull json info\"\"\"\n",
    "                    jsonFile = os.path.join(dataDir,i,j,k,m)\n",
    "                    with open(jsonFile) as f:\n",
    "                        jsonDict = json.load(f)\n",
    "\n",
    "                    \"\"\" image_description\"\"\"\n",
    "                    imageList = imageDict[jsonDict[\"SeriesDescription\"]]\n",
    "                    if len(imageList) > 1:\n",
    "                        imageDesc = imageList[0] + \" \" + imageList[1]\n",
    "                    else:\n",
    "                        imageDesc = imageList[0]\n",
    "\n",
    "                    \"\"\" scan_type\"\"\"\n",
    "                    scanType = scanDict[imageList[0]]\n",
    "\n",
    "                    \"\"\" image_num_dimensions \"\"\"\n",
    "                    if scanType == \"fMRI\":\n",
    "                        imgDim = 4\n",
    "                    else:\n",
    "                        imgDim = 3\n",
    "\n",
    "                    \"\"\" key = nda column name\"\"\"\n",
    "                    rowDict = {\n",
    "                        'src_subject_id': i, \n",
    "                        'interview_date': acqDate, \n",
    "                        'interview_age': numMonths,\n",
    "                        'sex': dicomHead[0x10,0x40].value,\n",
    "                        'image_description': imageDesc,\n",
    "                        'scan_type': scanType,\n",
    "                        'scan_object': \"Live\",\n",
    "                        'image_file_format': \"NIFTI\",\n",
    "                        'image_modality': \"MRI\",\n",
    "                        'transformation_performed': \"No\",\n",
    "                        'scanner_manufacturer_pd': jsonDict[\"Manufacturer\"],\n",
    "                        'scanner_type_pd': jsonDict[\"ManufacturersModelName\"],\n",
    "                        'scanner_software_versions_pd': dicomHead.SoftwareVersions,\n",
    "                        'magnetic_field_strength': jsonDict[\"MagneticFieldStrength\"],\n",
    "                        'mri_repetition_time_pd': jsonDict[\"RepetitionTime\"],\n",
    "                        'mri_echo_time_pd': jsonDict[\"EchoTime\"],\n",
    "                        'flip_angle': jsonDict[\"FlipAngle\"],\n",
    "                        'acquisition_matrix': \"TODO\",\n",
    "                        'mri_field_of_view_pd': \"TODO\",\n",
    "                        'patient_position': dicomHead.PatientPosition,\n",
    "                        'photomet_interpret': dicomHead[0x28,0x04].value,\n",
    "                        'image_num_dimensions': imgDim,\n",
    "                        'image_extent1': \"TODO\"\n",
    "                    }\n",
    "\n",
    "                    if scanType == \"fMRI\":\n",
    "                        rowDict[\"experiment_id\"] = imageList[2]\n",
    "\n",
    "                    if imageDesc == \"DWI\":\n",
    "                        rowDict[\"bvek_bval_files\"] = \"Yes\"\n",
    "\n",
    "\n",
    "                    \"\"\"## write appropriate columns to csv\"\"\"\n",
    "                    AppendCsv(outFile, rowDict, ndaColumns)\n",
    "\n",
    "                \"\"\"# clean unpacked tar file\"\"\"\n",
    "                if os.path.exists(os.path.join(outDir, \"home\")):\n",
    "                    shutil.rmtree(os.path.join(outDir, \"home\"))\n",
    "\n",
    "\"\"\" Add back first column\"\"\"\n",
    "PrependLine(outFile, \"image,03\")\n",
    "# hold = pd.read_csv(outFile)\n",
    "# print(hold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
